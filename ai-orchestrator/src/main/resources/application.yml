server:
  port: 8085
spring:
  application:
    name: ai-orchestrator
  ai:
    openai:
      api-key: ${OPENAI_API_KEY:dummy}
      chat:
        options:
          model: gpt-4o-mini
    mcp:
      client:
        enabled: true
        sse:
          connections:
            docs:
              url: ${MCP_SSE_URL:https://mcp.example.com}
              sse-endpoint: /sse
dubbo:
  application:
    name: ai-orchestrator
  registry:
    address: N/A
rpc:
  graph-service:
    url: dubbo://127.0.0.1:20880
  semantic-service:
    url: dubbo://127.0.0.1:20881
orchestrator:
  memory:
    type: local
    max-messages: 20
    redis:
      key-prefix: cdr:ai:memory:
      ttl: 12h
  llm:
    default-model: openai-default
    models:
      - name: openai-default
        provider: openai
        base-url: https://api.openai.com/v1
        api-key: ${OPENAI_API_KEY:dummy}
        model: gpt-4o-mini
        description: 默认 OpenAI 兼容模型
      - name: glm
        provider: glm
        base-url: https://open.bigmodel.cn/api/paas/v4
        api-key: ${GLM_API_KEY:dummy}
        model: glm-4
        description: 智谱 GLM-4
      - name: deepseek
        provider: deepseek
        base-url: https://api.deepseek.com/v1
        api-key: ${DEEPSEEK_API_KEY:dummy}
        model: deepseek-chat
        description: DeepSeek Chat
